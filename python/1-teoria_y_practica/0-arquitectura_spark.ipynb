{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Arquitectura Spark"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como hemos visto anteriormente, un cluster es una colección de nodos, un cluster Databricks tiene un nodo Driver y uno o más nodos worker, a menos que un nodo sea básicamente una máquina individual. Como estamos en Azure, esta será una de las \"virtual machines\" de Azure cloud. Cada una de las \"virtual machines\" de Azure suele tener al menos cuatro núcleos (cores), si no más. \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/1zpZCM8V/db23.png\"></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En un cluster Databricks, el driver ejecuta su programa driver en la JVM, en el nodo driver y crea este SparkContext. Como su nombre indica, el programa driver dirige el procesamiento y no realiza ninguno de los cálculos necesarios. Por ejemplo, se comunica con el cluster manager para asignar recursos, identifica el número de jobs, stages y tasks a crear, de forma que el trabajo pueda ser paralelizado. Cada uno de los nodos worker ejecutará las JVM. En una arquitectura Spark estándar, puede haber más de un Executor ejecutándose en un nodo y compartiendo recursos. Pero Databricks restringe eso a un solo Executor ejecutándose en una JVM. Y eso se considera la configuración más óptima y fácil de gestionar. El Executor, realiza todo el procesamiento de datos, así como la lectura y escritura de datos a fuentes de datos externas. \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/1XTvGhrx/db24.png\"></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada Executor tendrá una o más slots para ejecutar las tasks. Esto es generalmente equivalente al número de cores en los nodos worker. Como teníamos cuatro cores en nuestros nodos worker, tendremos cuatro slots aquí también. Los slots son sólo un lugar para ejecutar las tasks recibidas del programa driver. \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/WzW0rGjh/db25.png\"></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El driver es el que ejecuta la aplicación. Por ejemplo, cuando ejecutas un comando en el notebook de Databricks o ejecutas un Spark submit desde fuera del notebook de Databricks, se ejecuta como una aplicación en el driver.\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/k5L1RtqJ/db26.png\"></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una aplicación es dividida en jobs, stages y tasks por el programa driver. Spark intenta conseguir el mayor paralelismo posible. Esto se basa principalmente en cómo los datos pueden ser particionados y distribuidos a través del cluster, así como las stages que pueden ser paralelizadas. Lo importante aquí es que las tasks son los componentes de más bajo nivel que necesitan ser ejecutados. \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/kXZfpbRx/db27.png\"></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El driver asigna las tareas a un slot en el Executor y el Executor realiza estas operaciones, luego devuelve los resultados al driver. A continuación, el driver devuelve los resultados al usuario.\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/prkXdvzH/db28.png\"></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que entiendes cómo Spark paraliza la carga de trabajo, echemos un vistazo a cómo podemos escalar los clusters cuando lo necesitemos. Hay dos formas de escalar el cluster. La primera es tener nodos con más cores en ellos. Eso significa que puedes pasar, por ejemplo, de cuatro núcleos a seis cores en un nodo. Esto se llama escalado vertical, pero sólo se puede llegar hasta cierto punto antes de alcanzar el límite en el número máximo de cores disponibles en una virtual machine. \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/hPdcwV3n/db29.png\"></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente enfoque consiste en escalar horizontalmente el clúster. En este enfoque, añadimos más nodos trabajadores al clúster y este enfoque ayuda a escalar los clústeres que pueden procesar petabytes de datos. \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/V6QVJbWq/db30.png\"></center>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
