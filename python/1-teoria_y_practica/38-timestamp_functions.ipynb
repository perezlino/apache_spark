{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"92d8201a-93f0-4162-a7b7-da2869d106bd","showTitle":false,"title":""}},"source":["### ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Timestamp functions"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"c3070d6e-4cc2-4219-b95c-396a95e72cb8","showTitle":false,"title":""}},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- id: string (nullable = true)\n"," |-- input: string (nullable = true)\n","\n","+---+----------------------+\n","|id |input                 |\n","+---+----------------------+\n","|1  |2020-02-01 11 01 19 06|\n","|2  |2019-03-01 12 01 19 27|\n","|3  |2021-06-15 10 02 20 44|\n","+---+----------------------+\n","\n"]}],"source":["from pyspark.sql.functions import *\n","\n","data = [['1','2020-02-01 11 01 19 06'],\n","        ['2','2019-03-01 12 01 19 27'],\n","        ['3','2021-06-15 10 02 20 44']\n","       ]\n","\n","df = spark.createDataFrame(data,['id','input'])\n","df.printSchema()\n","df.show(truncate=False)"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"be079097-4e82-4cd0-9c06-a02642aa3fcf","showTitle":false,"title":""}},"source":["#### current_timestamp( )"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"c0db0c0a-21a7-45ac-8ac5-e25c33cbd32b","showTitle":false,"title":""}},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- id: string (nullable = true)\n"," |-- input: string (nullable = true)\n"," |-- current_timestamp: timestamp (nullable = false)\n","\n","+---+----------------------+-----------------------+\n","|id |input                 |current_timestamp      |\n","+---+----------------------+-----------------------+\n","|1  |2020-02-01 11 01 19 06|2023-01-12 23:11:16.282|\n","|2  |2019-03-01 12 01 19 27|2023-01-12 23:11:16.282|\n","|3  |2021-06-15 10 02 20 44|2023-01-12 23:11:16.282|\n","+---+----------------------+-----------------------+\n","\n"]}],"source":["df_modif = df.withColumn('current_timestamp',current_timestamp())\n","\n","df_modif.printSchema()\n","df_modif.show(truncate=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"133d8f43-0cdc-4bec-93ba-4a435c20f07d","showTitle":false,"title":""}},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- current_timestamp: timestamp (nullable = false)\n","\n","+-----------------------+\n","|current_timestamp      |\n","+-----------------------+\n","|2023-01-12 23:11:16.754|\n","|2023-01-12 23:11:16.754|\n","|2023-01-12 23:11:16.754|\n","+-----------------------+\n","\n"]}],"source":["df_modif = df.select(current_timestamp().alias('current_timestamp'))\n","\n","df_modif.printSchema()\n","df_modif.show(truncate=False)"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"f0a18a6b-c6f6-4c2a-b29b-76f0db369287","showTitle":false,"title":""}},"source":["#### to_timestamp( )\n","\n","Convierte un string timestamp a un formato de tipo Timestamp."]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"30f814d0-ac30-4138-b14e-c306592b0feb","showTitle":false,"title":""}},"source":["##### String a Timestamp"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"6fb05303-4e6a-4603-acbd-8bf8a565fe39","showTitle":false,"title":""}},"source":["Ejemplo 1"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"9522d5ba-3288-40db-ad66-ba831ea9f058","showTitle":false,"title":""}},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- input: string (nullable = true)\n"," |-- fecha_nueva: timestamp (nullable = true)\n","\n","+----------------------+----------------------+\n","|input                 |fecha_nueva           |\n","+----------------------+----------------------+\n","|2020-02-01 11 01 19 06|2020-02-01 11:01:19.06|\n","|2019-03-01 12 01 19 27|2019-03-01 12:01:19.27|\n","|2021-06-15 10 02 20 44|2021-06-15 10:02:20.44|\n","+----------------------+----------------------+\n","\n"]}],"source":["df_modif = df.select(col('input'),to_timestamp(col('input'),'yyyy-MM-dd HH mm ss SSS').alias('fecha_nueva'))\n","\n","df_modif.printSchema()\n","df_modif.show(truncate=False)"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"602dd05d-3bcb-49cf-8925-0d6b77a29c9c","showTitle":false,"title":""}},"source":["Ejemplo 2"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"252f9322-cf5e-445e-af3c-6666c3f488c5","showTitle":false,"title":""}},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- id: string (nullable = true)\n"," |-- input: string (nullable = true)\n","\n","+---+----------+\n","|id |input     |\n","+---+----------+\n","|1  |2020-02-01|\n","|2  |2019-03-07|\n","|3  |2021-06-10|\n","+---+----------+\n","\n"]}],"source":["from pyspark.sql.functions import *\n","\n","data = [['1','2020-02-01'],\n","        ['2','2019-03-07'],\n","        ['3','2021-06-10']\n","       ]\n","\n","df = spark.createDataFrame(data,['id','input'])\n","df.printSchema()\n","df.show(truncate=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"62d27d55-02c1-4d71-b579-b46c5d379408","showTitle":false,"title":""}},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+----------+---------+\n","| id|     input|timestamp|\n","+---+----------+---------+\n","|  1|2020-02-01|     null|\n","|  2|2019-03-07|     null|\n","|  3|2021-06-10|     null|\n","+---+----------+---------+\n","\n"]}],"source":["df_timestamp = df.withColumn(\"timestamp\", to_timestamp(col('input'), 'yyyy-MM-dd HH:mm:ss'))\n","\n","df_timestamp.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"be12f8fa-6018-4036-9801-c2ff8d3a15f5","showTitle":false,"title":""}},"source":["Ejemplo 3"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"5366f10b-63e5-4ab8-94a1-5a48963436f5","showTitle":false,"title":""}},"outputs":[{"name":"stdout","output_type":"stream","text":["+------+----+-----+---------+---------------------+----------+--------+-------------------------------------------------------+\n","|raceId|year|round|circuitId|name                 |date      |time    |url                                                    |\n","+------+----+-----+---------+---------------------+----------+--------+-------------------------------------------------------+\n","|1     |2009|1    |1        |Australian Grand Prix|2009-03-29|06:00:00|http://en.wikipedia.org/wiki/2009_Australian_Grand_Prix|\n","|2     |2009|2    |2        |Malaysian Grand Prix |2009-04-05|09:00:00|http://en.wikipedia.org/wiki/2009_Malaysian_Grand_Prix |\n","|3     |2009|3    |17       |Chinese Grand Prix   |2009-04-19|07:00:00|http://en.wikipedia.org/wiki/2009_Chinese_Grand_Prix   |\n","+------+----+-----+---------+---------------------+----------+--------+-------------------------------------------------------+\n","only showing top 3 rows\n","\n"]}],"source":["df_races = spark.read.format(\"csv\").\\\n","           option(\"header\",True).\\\n","           option(\"sep\",\",\").\\\n","           load('/FileStore/tables/raw/races.csv')\n","\n","df_races.show(n=3, truncate=False, vertical=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"b5933c59-afe7-4e71-8694-0f703f00cbb7","showTitle":false,"title":""}},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- raceId: string (nullable = true)\n"," |-- year: string (nullable = true)\n"," |-- round: string (nullable = true)\n"," |-- circuitId: string (nullable = true)\n"," |-- name: string (nullable = true)\n"," |-- date: string (nullable = true)\n"," |-- time: string (nullable = true)\n"," |-- url: string (nullable = true)\n","\n"]}],"source":["df_races.printSchema()"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"5a238f5b-722f-48e9-8acc-8b167f1e6a1c","showTitle":false,"title":""}},"outputs":[{"name":"stdout","output_type":"stream","text":["+------+----+-----+---------+--------------------+----------+--------+--------------------+-------------------+\n","|raceId|year|round|circuitId|                name|      date|    time|                 url|          timestamp|\n","+------+----+-----+---------+--------------------+----------+--------+--------------------+-------------------+\n","|     1|2009|    1|        1|Australian Grand ...|2009-03-29|06:00:00|http://en.wikiped...|2009-03-29 06:00:00|\n","|     2|2009|    2|        2|Malaysian Grand Prix|2009-04-05|09:00:00|http://en.wikiped...|2009-04-05 09:00:00|\n","|     3|2009|    3|       17|  Chinese Grand Prix|2009-04-19|07:00:00|http://en.wikiped...|2009-04-19 07:00:00|\n","|     4|2009|    4|        3|  Bahrain Grand Prix|2009-04-26|12:00:00|http://en.wikiped...|2009-04-26 12:00:00|\n","|     5|2009|    5|        4|  Spanish Grand Prix|2009-05-10|12:00:00|http://en.wikiped...|2009-05-10 12:00:00|\n","|     6|2009|    6|        6|   Monaco Grand Prix|2009-05-24|12:00:00|http://en.wikiped...|2009-05-24 12:00:00|\n","|     7|2009|    7|        5|  Turkish Grand Prix|2009-06-07|12:00:00|http://en.wikiped...|2009-06-07 12:00:00|\n","|     8|2009|    8|        9|  British Grand Prix|2009-06-21|12:00:00|http://en.wikiped...|2009-06-21 12:00:00|\n","|     9|2009|    9|       20|   German Grand Prix|2009-07-12|12:00:00|http://en.wikiped...|2009-07-12 12:00:00|\n","|    10|2009|   10|       11|Hungarian Grand Prix|2009-07-26|12:00:00|http://en.wikiped...|2009-07-26 12:00:00|\n","|    11|2009|   11|       12| European Grand Prix|2009-08-23|12:00:00|http://en.wikiped...|2009-08-23 12:00:00|\n","|    12|2009|   12|       13|  Belgian Grand Prix|2009-08-30|12:00:00|http://en.wikiped...|2009-08-30 12:00:00|\n","|    13|2009|   13|       14|  Italian Grand Prix|2009-09-13|12:00:00|http://en.wikiped...|2009-09-13 12:00:00|\n","|    14|2009|   14|       15|Singapore Grand Prix|2009-09-27|12:00:00|http://en.wikiped...|2009-09-27 12:00:00|\n","|    15|2009|   15|       22| Japanese Grand Prix|2009-10-04|05:00:00|http://en.wikiped...|2009-10-04 05:00:00|\n","|    16|2009|   16|       18|Brazilian Grand Prix|2009-10-18|16:00:00|http://en.wikiped...|2009-10-18 16:00:00|\n","|    17|2009|   17|       24|Abu Dhabi Grand Prix|2009-11-01|11:00:00|http://en.wikiped...|2009-11-01 11:00:00|\n","|    18|2008|    1|        1|Australian Grand ...|2008-03-16|04:30:00|http://en.wikiped...|2008-03-16 04:30:00|\n","|    19|2008|    2|        2|Malaysian Grand Prix|2008-03-23|07:00:00|http://en.wikiped...|2008-03-23 07:00:00|\n","|    20|2008|    3|        3|  Bahrain Grand Prix|2008-04-06|11:30:00|http://en.wikiped...|2008-04-06 11:30:00|\n","+------+----+-----+---------+--------------------+----------+--------+--------------------+-------------------+\n","only showing top 20 rows\n","\n"]}],"source":["df_timestamp = df_races.withColumn(\"timestamp\", to_timestamp(concat(col('date'), lit(' '), col('time')), 'yyyy-MM-dd HH:mm:ss'))\n","\n","df_timestamp.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"4861fb0b-2327-4601-bab8-0032e5610b47","showTitle":false,"title":""}},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- raceId: string (nullable = true)\n"," |-- year: string (nullable = true)\n"," |-- round: string (nullable = true)\n"," |-- circuitId: string (nullable = true)\n"," |-- name: string (nullable = true)\n"," |-- date: string (nullable = true)\n"," |-- time: string (nullable = true)\n"," |-- url: string (nullable = true)\n"," |-- timestamp: timestamp (nullable = true)\n","\n"]}],"source":["df_timestamp.printSchema()"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"f6e57eb9-8258-477f-b7ee-7e8384fa5536","showTitle":false,"title":""}},"source":["##### mm/dd/yyyy a Timestamp"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"5813bc2a-0171-4cec-a95f-01c48868eb5e","showTitle":false,"title":""}},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- date_str: string (nullable = true)\n","\n","+----------+\n","|  date_str|\n","+----------+\n","|11/25/1991|\n","|12/24/1992|\n","|10/15/1994|\n","+----------+\n","\n"]}],"source":["from pyspark.sql.functions import *\n","\n","df = spark.createDataFrame([('11/25/1991',),('12/24/1992',),('10/15/1994',)],['date_str'])\n","\n","df.printSchema()\n","df.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"2e2e6299-c13f-4719-98bf-1994a501c1ea","showTitle":false,"title":""}},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- date_str: string (nullable = true)\n"," |-- fecha_nueva: string (nullable = true)\n","\n","+----------+-------------------+\n","|date_str  |fecha_nueva        |\n","+----------+-------------------+\n","|11/25/1991|1991-11-25 00:00:00|\n","|12/24/1992|1992-12-24 00:00:00|\n","|10/15/1994|1994-10-15 00:00:00|\n","+----------+-------------------+\n","\n"]}],"source":["df_modif = df.select('date_str',from_unixtime(unix_timestamp('date_str','MM/dd/yyyy')).alias('fecha_nueva'))\n","\n","df_modif.printSchema()\n","df_modif.show(truncate=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"aa53c68f-0378-4999-a40b-91db25c0d240","showTitle":false,"title":""}},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- fecha_nueva: string (nullable = true)\n"," |-- timestamp: timestamp (nullable = true)\n","\n","+-------------------+-------------------+\n","|fecha_nueva        |timestamp          |\n","+-------------------+-------------------+\n","|1991-11-25 00:00:00|1991-11-25 00:00:00|\n","|1992-12-24 00:00:00|1992-12-24 00:00:00|\n","|1994-10-15 00:00:00|1994-10-15 00:00:00|\n","+-------------------+-------------------+\n","\n"]}],"source":["df_timestamp = df_modif.select(col('fecha_nueva'),to_timestamp(col('fecha_nueva'),'yyyy-MM-dd HH:mm:ss').alias('timestamp'))\n","\n","df_timestamp.printSchema()\n","df_timestamp.show(truncate=False)"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"431aa3c1-85a0-46b5-98ab-4c9d54a53df8","showTitle":false,"title":""}},"source":["#### hour( )\n","#### minute( )\n","#### second( )"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"a0044977-4197-4dd2-8161-805b883cd1b5","showTitle":false,"title":""}},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- id: string (nullable = true)\n"," |-- input: string (nullable = true)\n","\n","+---+----------------------+\n","|id |input                 |\n","+---+----------------------+\n","|1  |2020-02-01 11:01:19.06|\n","|2  |2019-03-01 12:01:19.27|\n","|3  |2021-06-15 10:02:20.44|\n","+---+----------------------+\n","\n"]}],"source":["from pyspark.sql.functions import *\n","\n","data = [['1','2020-02-01 11:01:19.06'],\n","        ['2','2019-03-01 12:01:19.27'],\n","        ['3','2021-06-15 10:02:20.44']\n","       ]\n","\n","df = spark.createDataFrame(data,['id','input'])\n","df.printSchema()\n","df.show(truncate=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"2453ef41-3976-415d-bec7-0ed93855a36c","showTitle":false,"title":""}},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- input: string (nullable = true)\n"," |-- hour: integer (nullable = true)\n"," |-- minute: integer (nullable = true)\n"," |-- second: integer (nullable = true)\n","\n","+----------------------+----+------+------+\n","|input                 |hour|minute|second|\n","+----------------------+----+------+------+\n","|2020-02-01 11:01:19.06|11  |1     |19    |\n","|2019-03-01 12:01:19.27|12  |1     |19    |\n","|2021-06-15 10:02:20.44|10  |2     |20    |\n","+----------------------+----+------+------+\n","\n"]}],"source":["df_modif = df.select(col('input'),\n","              hour(col('input')).alias('hour'),\n","              minute(col('input')).alias('minute'),\n","              second(col('input')).alias('second'),\n","             )\n","\n","df_modif.printSchema()\n","df_modif.show(truncate=False)"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"5724905c-ea4d-4a04-963f-19b895dd5791","showTitle":false,"title":""}},"source":["#### from_unixtime( )"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"146baac2-138a-49df-abbe-9eb08cd81ea0","showTitle":false,"title":""}},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- local_int: integer (nullable = true)\n"," |-- fecha_apertura: integer (nullable = true)\n","\n","+---------+--------------+\n","|local_int|fecha_apertura|\n","+---------+--------------+\n","|        0|    1100746394|\n","|        1|    1474410343|\n","|        2|    1116610009|\n","|        3|    1408024997|\n","+---------+--------------+\n","\n"]}],"source":["from pyspark.sql.functions import *\n","\n","data = [(0,1100746394),(1,1474410343),(2,1116610009),(3,1408024997)]\n","\n","columnas = ['local_id','fecha_apertura']\n","\n","df = spark.createDataFrame(data,'local_int INT, fecha_apertura INT')\n","\n","df.printSchema()\n","df.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"c71b7621-941b-4ea1-8389-8c86a8bc9d09","showTitle":false,"title":""}},"source":["##### Ejemplo 1\n","\n","UNIX epoch (Integer) a String (con formato Timestamp)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"55a5138d-a0cd-452b-88cc-28565d9dbdb6","showTitle":false,"title":""}},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- local_int: integer (nullable = true)\n"," |-- fecha_apertura: integer (nullable = true)\n"," |-- fecha_apertura_string: string (nullable = true)\n","\n","+---------+--------------+---------------------+\n","|local_int|fecha_apertura|fecha_apertura_string|\n","+---------+--------------+---------------------+\n","|0        |1100746394    |2004-11-18 02:53:14  |\n","|1        |1474410343    |2016-09-20 22:25:43  |\n","|2        |1116610009    |2005-05-20 17:26:49  |\n","|3        |1408024997    |2014-08-14 14:03:17  |\n","+---------+--------------+---------------------+\n","\n"]}],"source":["df_modif = df.withColumn('fecha_apertura_string', from_unixtime('fecha_apertura'))\n","\n","df_modif.printSchema()\n","df_modif.show(truncate=False)"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"1f88a942-a3a7-4ac0-be93-c0eab48b57d9","showTitle":false,"title":""}},"source":["##### Ejemplo 2\n","\n","UNIX epoch (Integer) a String\n","\n","Este ejemplo no se puede utilizar con date_format, dado que dicha función solo acepta día, mes y año y no horas y segundos."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"41179b1f-f5b8-4fe0-b6af-ecfdeed03d35","showTitle":false,"title":""}},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- local_int: integer (nullable = true)\n"," |-- fecha_apertura: integer (nullable = true)\n"," |-- fecha_apertura_string: string (nullable = true)\n","\n","+---------+--------------+------------------------------+\n","|local_int|fecha_apertura|fecha_apertura_string         |\n","+---------+--------------+------------------------------+\n","|0        |1100746394    |Thursday, Nov 18, 2004 2:53 AM|\n","|1        |1474410343    |Tuesday, Sep 20, 2016 10:25 PM|\n","|2        |1116610009    |Friday, May 20, 2005 5:26 PM  |\n","|3        |1408024997    |Thursday, Aug 14, 2014 2:03 PM|\n","+---------+--------------+------------------------------+\n","\n"]}],"source":["formato = 'EEEE, MMM d, yyyy h:mm a'\n","df_modif = df.withColumn('fecha_apertura_string', from_unixtime('fecha_apertura', formato))\n","\n","df_modif.printSchema()\n","df_modif.show(truncate=False)"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"ef33e816-f512-4bf1-ace9-341de116ef8f","showTitle":false,"title":""}},"source":["#### cast()"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"6d51faed-5474-48dc-b53a-0f76cf6d7e01","showTitle":false,"title":""}},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- local_int: integer (nullable = true)\n"," |-- fecha_apertura: integer (nullable = true)\n","\n","+---------+--------------+\n","|local_int|fecha_apertura|\n","+---------+--------------+\n","|        0|    1100746394|\n","|        1|    1474410343|\n","|        2|    1116610009|\n","|        3|    1408024997|\n","+---------+--------------+\n","\n"]}],"source":["from pyspark.sql.functions import *\n","\n","data = [(0,1100746394),(1,1474410343),(2,1116610009),(3,1408024997)]\n","\n","columnas = ['local_id','fecha_apertura']\n","\n","df = spark.createDataFrame(data,'local_int INT, fecha_apertura INT')\n","\n","df.printSchema()\n","df.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"934ae6b4-6d6e-4b2c-8a02-b00e5d4f4aee","showTitle":false,"title":""}},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- local_int: integer (nullable = true)\n"," |-- fecha_apertura: integer (nullable = true)\n"," |-- timestamp: timestamp (nullable = true)\n","\n","+---------+--------------+-------------------+\n","|local_int|fecha_apertura|timestamp          |\n","+---------+--------------+-------------------+\n","|0        |1100746394    |2004-11-18 02:53:14|\n","|1        |1474410343    |2016-09-20 22:25:43|\n","|2        |1116610009    |2005-05-20 17:26:49|\n","|3        |1408024997    |2014-08-14 14:03:17|\n","+---------+--------------+-------------------+\n","\n"]}],"source":["df_modif = df.withColumn('timestamp', col('fecha_apertura').cast('timestamp'))\n","\n","df_modif.printSchema()\n","df_modif.show(truncate=False)"]}],"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"language":"python","notebookMetadata":{"pythonIndentUnit":4},"notebookName":"38-timestamp_functions","widgets":{}},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
